{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A) Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_and_headers(filename):\n",
    "    data = None\n",
    "    with open(filename) as fp:\n",
    "        data = [x.strip().split(',') for x in fp.readlines()]\n",
    "    headers = data[0]\n",
    "    headers = np.asarray(headers)\n",
    "    class_field = len(headers) - 1\n",
    "    data_x = [[float(x[i]) for i in range(class_field)] for x in data[1:]]\n",
    "    data_x = np.asarray(data_x)\n",
    "    data_y = [[str(x[i]) for i in range(class_field, class_field + 1)] for x in data[1:]]\n",
    "    data_y = np.asarray(data_y)\n",
    "    return headers, data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers, train_x, train_y = data_and_headers('Data' + os.sep + 'hw2q1_train.csv')\n",
    "headers, test_x, test_y = data_and_headers('Data' + os.sep + 'hw2q1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Data')\n",
    "print('Number of features - ' + str(train_x.shape[1]))\n",
    "print('Number of target features - ' + str(train_y.shape[1]))\n",
    "print('Number of observations - ' + str(train_x.shape[0]))\n",
    "print('Number of observations in category R - ' + str(train_y[train_y=='R'].shape[0]))\n",
    "print('Number of observations in category M - ' + str(train_y[train_y=='M'].shape[0]))\n",
    "print()\n",
    "print('Testing Data')\n",
    "print('Number of features - ' + str(test_x.shape[1]))\n",
    "print('Number of target features - ' + str(test_y.shape[1]))\n",
    "print('Number of observations - ' + str(test_x.shape[0]))\n",
    "print('Number of observations in category R - ' + str(test_y[test_y=='R'].shape[0]))\n",
    "print('Number of observations in category M - ' + str(test_y[test_y=='M'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Normalization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, minima, maxima):\n",
    "    normal = np.copy(data)\n",
    "    normal = (normal - minima) / (maxima - minima)\n",
    "    return normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_train = normalize(train_x, np.amin(train_x, axis=0), np.amax(train_x, axis=0))\n",
    "normal_test = normalize(test_x, np.amin(train_x, axis=0), np.amax(train_x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Covariance of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = np.cov(normal_train, rowvar=False)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(15)\n",
    "im = axes.pcolor(covariance, cmap='CMRmap')\n",
    "fig.colorbar(im, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Eigenvalue and Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of covariance matrix - ' + str(covariance.shape))\n",
    "w,v = np.linalg.eig(covariance)\n",
    "print('Top 5 Eigenvalues - ' + ', '.join(['{:.3f}'.format(x) for x in sorted(w[np.argsort(w)[-5:]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Plot of Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(24)\n",
    "axes[0].bar(np.arange(60), w)\n",
    "axes[0].xaxis.grid()\n",
    "axes[0].yaxis.grid()\n",
    "axes[0].set_xlabel('eigenvectors')\n",
    "axes[0].set_ylabel('eigenvalues')\n",
    "axes[0].set_title('Plot of Variance captured by each eigenvector')\n",
    "axes[1].bar(np.arange(60), np.cumsum(w))\n",
    "axes[1].xaxis.grid()\n",
    "axes[1].yaxis.grid()\n",
    "axes[1].set_xlabel('eigenvectors')\n",
    "axes[1].set_ylabel('cumulative sum of eigenvalues')\n",
    "axes[1].set_title('Cumulative Contribution of eigenvalues')\n",
    "axes[2].plot(np.arange(60), np.cumsum(w)/np.sum(w))\n",
    "axes[2].xaxis.grid()\n",
    "axes[2].yaxis.grid()\n",
    "axes[2].set_xlabel('eigenvectors')\n",
    "axes[2].set_ylabel('cumulative sum of eigenvalues (scaled)')\n",
    "axes[2].set_title('Scaled Cumulative Contribution of eigenvalues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv) PCA with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomps = [2,4,6,8,10,20,40,60]\n",
    "pca = [PCA(n_components=x).fit(normal_train) for x in ncomps]\n",
    "cls = [KNeighborsClassifier(n_neighbors=3, metric='euclidean').fit(pca[i].transform(normal_train), np.ravel(train_y)) for i in range(len(ncomps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = cls[4].predict(pca[4].transform(normal_test))\n",
    "true4 = np.ravel(test_y)\n",
    "with open('q1iv.csv','w') as fp:\n",
    "    fp.write(', '.join(['Component' + str(i) for i in range(1,ncomps[4]+1)])+', Class, Class\\n')\n",
    "    transformed = pca[4].transform(normal_test)\n",
    "    for i in range(len(transformed)):\n",
    "        fp.write(', '.join([str(x) for x in transformed[i]]))\n",
    "        fp.write(', ' + str(true4[i]))\n",
    "        fp.write(', ' + str(pred4[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "axes.bar(ncomps, [cls[i].score(pca[i].transform(normal_test), np.ravel(test_y)) for i in range(len(ncomps))])\n",
    "axes.set_xlabel('Number of Components')\n",
    "axes.set_ylabel('Accuracy of Prediction')\n",
    "axes.set_title('Performance of Classification for all components')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) Standardization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data, mean, sd):\n",
    "    standard = np.copy(data)\n",
    "    standard = (standard - mean) / sd\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_train = standardize(train_x, np.mean(train_x, axis=0), np.std(train_x, axis=0))\n",
    "standard_test = standardize(test_x, np.mean(train_x, axis=0), np.std(train_x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Covariance of Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = np.cov(standard_train, rowvar=False)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(15)\n",
    "im = axes.pcolor(covariance, cmap='CMRmap')\n",
    "fig.colorbar(im, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) Eigenvalue and Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of covariance matrix - ' + str(covariance.shape))\n",
    "w,v = np.linalg.eig(covariance)\n",
    "print('Top 5 Eigenvalues - ' + ', '.join(['{:.3f}'.format(x) for x in sorted(w[np.argsort(w)[-5:]])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iii) Plot of Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(24)\n",
    "axes[0].bar(np.arange(60), w)\n",
    "axes[0].xaxis.grid()\n",
    "axes[0].yaxis.grid()\n",
    "axes[0].set_xlabel('eigenvectors')\n",
    "axes[0].set_ylabel('eigenvalues')\n",
    "axes[0].set_title('Plot of Variance captured by each eigenvector')\n",
    "axes[1].bar(np.arange(60), np.cumsum(w))\n",
    "axes[1].xaxis.grid()\n",
    "axes[1].yaxis.grid()\n",
    "axes[1].set_xlabel('eigenvectors')\n",
    "axes[1].set_ylabel('cumulative sum of eigenvalues')\n",
    "axes[1].set_title('Cumulative Contribution of eigenvalues')\n",
    "axes[2].plot(np.arange(60), np.cumsum(w)/np.sum(w))\n",
    "axes[2].xaxis.grid()\n",
    "axes[2].yaxis.grid()\n",
    "axes[2].set_xlabel('eigenvectors')\n",
    "axes[2].set_ylabel('cumulative sum of eigenvalues (scaled)')\n",
    "axes[2].set_title('Scaled Cumulative Contribution of eigenvalues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (iv) PCA with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomps = [2,4,6,8,10,20,40,60]\n",
    "pca = [PCA(n_components=x).fit(standard_train) for x in ncomps]\n",
    "cls = [KNeighborsClassifier(n_neighbors=3, metric='euclidean').fit(pca[i].transform(standard_train), np.ravel(train_y)) for i in range(len(ncomps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = cls[4].predict(pca[4].transform(standard_test))\n",
    "true4 = np.ravel(test_y)\n",
    "with open('q1v.csv','w') as fp:\n",
    "    fp.write(', '.join(['Component' + str(i) for i in range(1,ncomps[4]+1)])+', Class, Class\\n')\n",
    "    transformed = pca[4].transform(standard_test)\n",
    "    for i in range(len(transformed)):\n",
    "        fp.write(', '.join([str(x) for x in transformed[i]]))\n",
    "        fp.write(', ' + str(true4[i]))\n",
    "        fp.write(', ' + str(pred4[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "axes.bar(ncomps, [cls[i].score(pca[i].transform(standard_test), np.ravel(test_y)) for i in range(len(ncomps))])\n",
    "axes.set_xlabel('Number of Components')\n",
    "axes.set_ylabel('Accuracy of Prediction')\n",
    "axes.set_title('Performance of Classification for all components')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
